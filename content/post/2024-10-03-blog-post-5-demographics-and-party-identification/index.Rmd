---
title: 'Blog Post 5: Demographics and Party Identification'
author: Alex Heuss
date: '2024-10-03'
slug: blog-post-5-demographics-and-party-identification
categories: []
tags: []
---

```{r, load packages, echo=FALSE, message=FALSE}
library(car)
library(caret)
library(CVXR)
library(glmnet)
library(kableExtra)
library(maps)
library(RColorBrewer)
library(sf)
library(tidyverse)
library(viridis)
library(kableExtra)
library(mice)
```

## Discussion of the Predicitive Power of Demographics and Party ID

In class this week, we discussed the power of demographic variables in predicting election outcomes. The paper we read this week, Kim & Zilinsky's "Division does not imply predictability: Demographics
continue to reveal little about voting and partisanship", provided empirical evidence that demographic data can predict vote choice with an accuracy of approximately 63%. They also found though that party is more predictive, especially when combined with demographics. This motivates my own theory of the importance of partisan identification.

My theory around election prediction involves a rather pessimistic belief that a person's vote, especially in recent elections, can likely be fairly accurately predicted by partisan identification alone. I believe that the country has become increasingly polarized and that people vote based on their party more than other factors like the economy or a candidate's particular policies. 

I found and cleaned data for both national (Gallup and Pew Research) and state (ANES estimates) party identification historically. The graph below shows the relationship between national party ID "swing" between the year before an election and election year and the national popular vote. The "swing" measure attempts to get a feel for party momentum going into the election year. 

```{r, creating national dataset, echo=FALSE, message=FALSE, show_col_types=FALSE}
# Complete except for turnout and demographics

# National Dataset
nat_pop <- read_csv("data/popvote_1948_2020.csv")
nat_party <- read_csv("data/national_party_id.csv") |>
  mutate(swing1 = percent - year_prior,
         swing1_2p = two_party_percent - year_prior_2p) |>
  arrange(year) |>
  group_by(party) |>
  mutate(prior_election = lag(percent, 1),
         prior_election_2p = lag(two_party_percent, 1),
         swing4 = percent - prior_election, 
         swing4_2p = two_party_percent - prior_election_2p)
nat_polls <- read_csv("data/polls/national_polls_1968-2024.csv") |>
  mutate(party = ifelse(party == "DEM", "democrat", "republican")) |>
  filter(weeks_left <= 30) |>
  group_by(party, year, weeks_left) |>
  summarize(nat_poll = mean(poll_support)) |>
  pivot_wider(names_from = weeks_left, values_from = nat_poll)
colnames(nat_polls)[3:33] <- paste0("nat_weeks_left_", 0:30)
nat_econ_q2 <- read_csv("data/econ/fred_econ.csv") |>
  filter(year >= 1968 & quarter == 2) |>
  rename(q2_gdp_growth = GDP_growth_quarterly,
         q2_rdpi_growth = RDPI_growth_quarterly) |>
  select(year, q2_gdp_growth, q2_rdpi_growth)
nat_econ_ann <- read_csv("data/econ/fred_econ.csv") |>
  filter(year >= 1968) |>
  group_by(year) |>
  summarize(GDP = mean(GDP),
            RDPI = mean(RDPI),
            nat_unemployment = mean(unemployment),
            stock_adj_close = mean(sp500_adj_close))
nat_data <- 
  nat_pop |>
  left_join(nat_party, by = c("year", "party")) |>
  left_join(nat_polls, by = c("year", "party")) |>
  filter(year >= 1968) |>
  left_join(nat_econ_q2, by = "year") |>
  left_join(nat_econ_ann, by = "year")

```

```{r, creating state dataset, echo=FALSE, message=FALSE}
# State Dataset
#Load in EC data and subset it as a state abbreviation/full name key
ec <- read_csv("data/corrected_ec_1948_2024.csv")
stateabs <- ec |>
  filter(year == 2024) |>
  select(state, stateab)
# Literally so much code to make state-level party
anes_party_id <- 
  read_csv("data/anes_timeseries_cdf_csv_20220916.csv") |>
  select(VCF0004, VCF0901b, VCF0302) |>
  rename(year = VCF0004,
         stateab = VCF0901b,
         party = VCF0302) |>
  filter(year >= 1968) |>
  left_join(stateabs, by = "stateab") |>
  select(year, state, party) |>
  mutate(party = case_when(party == 1 ~ "republican",
                           party == 2 ~ "independent",
                           party == 3 ~ "none",
                           party == 4 ~ "other",
                           party == 5 ~ "democrat")) |>
  filter(party == "republican" | party == "democrat" | party == "independent") |>
  group_by(year, state, party) |>
  summarize(count = n()) |>
  pivot_wider(names_from = party, values_from = count) |>
  mutate(democrat = ifelse(is.na(democrat), 0, democrat),
         republican = ifelse(is.na(republican), 0, republican),
         independent = ifelse(is.na(independent), 0, independent),
         state_total = sum(democrat, independent, republican),
         two_party_total = sum(democrat, republican),
         dem_perc = round((democrat/state_total)*100, 2),
         rep_perc = round((republican/state_total)*100, 2),
         ind_perc = round((independent/state_total)*100, 2),
         dem_2p_perc = round((democrat/two_party_total)*100, 2),
         rep_2p_perc = round((republican/two_party_total)*100, 2)) |>
  select(-democrat, -republican, -independent, -state_total, -two_party_total) |>
  pivot_longer(cols = c(dem_perc, rep_perc),
               names_to = "party", 
               values_to = "state_party_perc") |>
  mutate(party = ifelse(party == "dem_perc", "democrat", "republican"),
         state_2p_perc = ifelse(party == "democrat", dem_2p_perc, rep_2p_perc),
         state_ind_perc = ind_perc) |>
  select(-ind_perc, -dem_2p_perc, -rep_2p_perc) |>
  arrange(year) |>
  group_by(state, party) |>
  mutate(prior_election = lag(state_party_perc, 1),
         prior_election_2p = lag(state_2p_perc, 1),
         state_swing4 = state_party_perc - prior_election, 
         state_swing4_2p = state_2p_perc - prior_election_2p)

# State Econ
state_econ <- read_csv("data/econ/Historical_State_Unemployment.csv") |>
  mutate(year = format(as.Date(date), "%Y")) |>
  mutate(year = as.double(year)) |>
  group_by(state, year) |>
  summarize(avg_state_unemployment = mean(unemployment))

# State Level Polls
missing_state_polls <- 
  read_csv("data/polls/missing_poll_states_csv.csv")
state_polls_wider <- 
  read_csv("data/polls/state_polls_1968-2024.csv") 
state_polls_wider <- rbind(state_polls_wider, missing_state_polls) |>
  mutate(state = ifelse(state == "Nebraska Cd 2", "Nebraska", state),
         party = ifelse(party == "DEM", "democrat", "republican"))|>
  filter(weeks_left <= 30) |>
  group_by(year, state, weeks_left, party) |>
  summarize(poll_support = mean(poll_support)) |>
  pivot_wider(names_from = weeks_left, values_from = poll_support)

colnames(state_polls_wider)[4:34] <- paste0("poll_weeks_left_", 0:30)

# Historical State Popular Vote
state_pop <- read_csv("data/state_popvote_1948_2020.csv")

# Nat Vote Mutated for State Merge
nat_pop_state <- 
  nat_pop |>
  rename(nat_pv = pv,
         nat_2pv = pv2p,
         nat_winner = winner) |>
  select(-candidate) |>
  arrange(year) |>
  group_by(party) |>
  mutate(nat_pv_lag1 = lag(nat_pv, 1),
         nat_2pv_lag1 = lag(nat_2pv, 1))
state_data <- 
  state_polls_wider |>
  left_join(state_pop, by = c("year", "state")) |>
  left_join(state_econ, by = c("year", "state")) |>
  left_join(nat_pop_state, by = c("year", "party")) |>
  arrange(year) |>
  group_by(state, party) |>
  mutate(D_pv_lag1 = ifelse(year == 2024, lag(D_pv, 1), D_pv_lag1),
         R_pv_lag1 = ifelse(year == 2024, lag(R_pv, 1), R_pv_lag1),
         D_pv_lag2 = ifelse(year == 2024, lag(D_pv, 2), D_pv_lag2),
         R_pv_lag2 = ifelse(year == 2024, lag(R_pv, 2), R_pv_lag2),
         D_pv2p_lag1 = ifelse(year == 2024, lag(D_pv2p, 1), D_pv2p_lag1),
         R_pv2p_lag1 = ifelse(year == 2024, lag(R_pv2p, 1), R_pv2p_lag1),
         D_pv2p_lag2 = ifelse(year == 2024, lag(D_pv2p, 2), D_pv2p_lag2),
         R_pv2p_lag2 = ifelse(year == 2024, lag(R_pv2p, 2), R_pv2p_lag2),
         state_pv = ifelse(party == "democrat", D_pv, R_pv),
         state_2pv = ifelse(party == "democrat", D_pv2p, R_pv2p),
         state_pv_lag1 = ifelse(party == "democrat", D_pv_lag1, R_pv_lag1),
         state_pv_lag2 = ifelse(party == "democrat", D_pv_lag2, R_pv_lag2),
         state_2pv_lag1 = ifelse(party == "democrat", D_pv2p_lag1, R_pv2p_lag1),
         state_2pv_lag2 = ifelse(party == "democrat", D_pv2p_lag2, R_pv2p_lag2)) |>
  select(-D_pv, -R_pv, -D_pv2p, -R_pv2p, -D_pv_lag1, -R_pv_lag1, -D_pv_lag2, -R_pv_lag2, -D_pv2p_lag1, -R_pv2p_lag1, -D_pv2p_lag2, -R_pv2p_lag2) |>
  rename(state_margin = margin) |>
  left_join(anes_party_id, by = c("year", "state", "party"))
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
demographics <- read_csv("data/demographics.csv") |>
  group_by(year, state) |>
  mutate(hispanic = sum(c(hispanic_white, hispanic_black, hispanic_american_indian, hispanic_asian_pacific_islander, hispanic_other_race, hispanic_two_or_more_races), na.rm = TRUE),
         age_18_to_29 = sum(c(age_18_to_19, age_20, age_21, age_22_to_24, age_25_to_29), na.rm=TRUE),
         age_30_to_44 = sum(c(age_30_to_34, age_35_to_44), na.rm = TRUE),
         age_45_to_59 = sum(c(age_45_to_54, age_55_to_59), na.rm = TRUE),
         age_60_to_74 = sum(c(age_60_to_61, age_62_to_64, age_65_to_74), na.rm = TRUE),
         ) |>
  select(-1, -(9:38), -total_pop, -under18)

toss_lean_likely_states <- c("AZ", "GA", "MI", "NV", "NC", "PA", "WI", "ME", "MN", "NH", "NM", "VA", "FL", "TX")

i = 0

for (state in toss_lean_likely_states) {
  # Load in the state's voter files
  voter_file_state_data <- 
    read_csv(paste0("data/state_1pc_samples_aug24/", state, "_sample.csv")) 
  
  # Count the number of voters in the voter files
  voter_file_total_voters <- nrow(voter_file_state_data)
  
  # Clean the data a lot
  voter_file_state_data <- 
    voter_file_state_data |>
    filter(sii_deceased == 0) |>
    rename(stateab = sii_state) |>
    left_join(stateabs, by = "stateab") |>
    mutate(total_voters = voter_file_total_voters,
           age_18_to_29 = ifelse(sii_age_range == "A", 1, 0),
           age_30_to_44 = ifelse(sii_age >= 30 & sii_age <= 44, 1, 0),
           age_45_to_59 = ifelse(sii_age >= 45 & sii_age <= 59, 1, 0),
           age_60_to_74 = ifelse(sii_age >= 60 & sii_age <= 74, 1, 0),
           age_75_to_84 = ifelse(sii_age >= 75 & sii_age <= 84, 1, 0),
           age_85_and_over = ifelse(sii_age >= 85, 1, 0),
           white = ifelse(sii_race == "W", 1, 0),
           black = ifelse(sii_race == "B", 1, 0), 
           american_indian = ifelse(sii_race == "N", 1, 0),
           asian_pacific_islander = ifelse(sii_race == "A", 1, 0),
           hispanic = ifelse(sii_race == "H", 1, 0),
           registered_dem = ifelse(svi_party_registration == "D", 1, 0),
           registered_rep = ifelse(svi_party_registration == "R", 1, 0),
           state_ind = ifelse(svi_party_registration == "U", 1, 0),
           less_than_college = ifelse(sii_education_level == "A" | sii_education_level == "E", 1, 0),
           bachelors = ifelse(sii_education_level == "B", 1, 0),
           graduate = ifelse(sii_education_level == "C", 1, 0)) |>
    select(-stateab, -sii_deceased, -sii_age, -sii_age_range, -sii_race, -sii_gender, -sii_race, -svi_party_registration, -sii_education_level, -sii_homeowner, -sii_married, -sii_urbanicity, -svi_vh_2020p, -svi_vh_2020p_party, -svi_vh_2020pp, -svi_vh_2020pp_party, -svi_vh_2020g, -svi_vh_2021p, -svi_vh_2021p_party, -svi_vh_2021g, -svi_vh_2022p, -svi_vh_2022p_party, -svi_vh_2022g, -svi_vh_2023p, -svi_vh_2023p_party, -svi_vh_2023g, -svi_vh_2024p, -svi_vh_2024p_party, -svi_vh_2024pp, -svi_vh_2024pp_party, -svi_vh_2024g, -svi_vote_all_general, -svi_vote_all_general_fed, -svi_vote_all_general_fed_pct, -svi_vote_all_general_midterm, -svi_vote_all_general_midterm_pct, -svi_vote_all_general_pres, -svi_vote_all_general_pres_pct, -svi_vote_all_offyear, -svi_vote_all_primary, -svi_vote_all_primary_pres, -svi_vote_all_primary_pres_pct, -svi_vote_all_primary_dem_votes, -svi_vote_all_primary_dem_votes_pct) |>
    group_by(state) |>
    summarize(total_voters = mean(total_voters),
              year = 2024,
              age_18_to_29 = sum(age_18_to_29, na.rm = TRUE)/total_voters,
              age_30_to_44 = sum(age_30_to_44, na.rm = TRUE)/total_voters,
              age_45_to_59 = sum(age_45_to_59, na.rm = TRUE)/total_voters,
              age_60_to_74 = sum(age_60_to_74, na.rm = TRUE)/total_voters,
              age_75_to_84 = sum(age_75_to_84, na.rm = TRUE)/total_voters,
              age_85_and_over = sum(age_85_and_over, na.rm = TRUE)/total_voters,
              white = sum(white)/total_voters,
              black = sum(black)/total_voters,
              american_indian = sum(american_indian)/total_voters,
              asian_pacific_islander = sum(asian_pacific_islander)/total_voters,
              hispanic = sum(hispanic)/total_voters,
              registered_dem = sum(registered_dem, na.rm = TRUE)/total_voters*100,
              registered_rep = sum(registered_rep, na.rm = TRUE)/total_voters*100,
              registered_ind = sum(state_ind, na.rm = TRUE)/total_voters*100,
              less_than_college = sum(less_than_college, na.rm = TRUE)/total_voters,
              bachelors = sum(bachelors, na.rm = TRUE)/total_voters,
              graduate = sum(graduate, na.rm = TRUE)/total_voters)
  
  # Subset to just party
  voter_file_party <- 
    voter_file_state_data |>
    select(state, year, registered_dem, registered_rep, registered_ind)
  
  # update party vars in state_data
  state_data <- 
    state_data |>
    left_join(voter_file_party, by = c("year", "state")) 
    
  if (i >= 1) {
    state_data <- 
      state_data |>
      mutate(registered_dem = coalesce(registered_dem.x, registered_dem.y), 
             registered_rep = coalesce(registered_rep.x, registered_rep.y),
             registered_ind = coalesce(registered_ind.x, registered_ind.y)) |>
      select(-registered_dem.x, -registered_dem.y, -registered_rep.x, -registered_rep.y, -registered_ind.x, -registered_ind.y)
  }
    
  state_data <- 
    state_data |>
    mutate(state_party_perc = case_when(year == 2024 & state==state & party == "democrat" ~ registered_dem,
                                        year == 2024 & state == state & party == "republican" ~ registered_rep,
                                        TRUE ~ state_party_perc),
            state_ind_perc = ifelse(year == 2024 & state == state, registered_ind, state_ind_perc),
            state_2p_perc = case_when(year == 2024 & state == state & party == "democrat" ~ registered_dem/(registered_dem + registered_rep),
                                      year == 2024 & state == state & party == "republican" ~ registered_rep/(registered_dem + registered_rep),
                                      TRUE ~ state_2p_perc))
  
  # Subset to just demographics and bind it with historical demographic data
  voter_file_demographics <- 
    voter_file_state_data |>
    select(-registered_dem, -registered_rep, -registered_ind, -total_voters)
  
  demographics <- rbind(demographics, voter_file_demographics)
  
  i = i + 1
}

```

```{r, finishing cleaning the data, echo=FALSE, message=FALSE}
state_data <- state_data |>
  select(-registered_dem, -registered_rep, -registered_ind) |>
  arrange(year) |>
  group_by(party, state) |>
  mutate(state_party_perc_lag1 = lag(state_party_perc, 1)) |>
  left_join((nat_party |> select(year, party, percent, two_party_percent, year_prior, year_prior_2p, prior_election, prior_election_2p) |> rename(nat_party_perc = percent, nat_2p_perc = two_party_percent, nat_party_lag1 = prior_election, nat_party_2p_lag1 = prior_election_2p)), by = c("year", "party")) |>
  mutate(state_party_perc = ifelse(is.na(state_party_perc) & year == 2024, nat_party_perc + (nat_party_lag1 - state_party_perc_lag1), state_party_perc))

state_data_swing <- 
  state_data |>
  filter(state %in% c("Georgia", "Michigan", "Pennsylvania", "North Carolina", "Wisconsin", "Nevada", "Arizona"))
  
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
nat_data |>
  mutate(Party = ifelse(party == "democrat", "Democrat", "Republican")) |>
  ggplot(aes(x = swing1, y = pv, color = Party)) +
  geom_point(color = "darkgray") + 
  geom_smooth(method = "lm", se=FALSE) + 
  scale_color_manual(values = c("#00AEF3", "#E81B23")) + 
  facet_wrap(~ Party) + 
  labs(x = "Change in Party ID Between the Year Prior to the Election and Election Year (Percentage Points)",
       y = "Popular Vote Share (%)",
       title = "Party ID Shifts and Presidential Popular Vote Share") + 
  theme_bw() + 
  theme(legend.position = "none")

```

This graph shows, intuitively, a rough positive correlation. Generally, when party identification is changing in a positive direction between the year prior to the election and the election itself (momentum), the vote share for that party is higher. 

Looking at the relationship between partisan identification and popular vote on the state level, the relationship between party identification swing and popular vote in the state is much less conclusive.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
state_data |>
  filter(state %in% c("Arizona", "Georgia", "Michigan", "North Carolina", "Ohio", "Nevada", "Pennsylvania")) |>
  filter(year >= 1992) |>
  ggplot(aes(x = state_swing4, y = state_pv, color = party)) +
  geom_point(color = "gray") +
  geom_smooth(method = "lm", se=FALSE) +
  scale_color_manual(values = c("#00AEF3", "#E81B23")) +
  facet_wrap(~ state) + 
  labs(x = "State Party ID Swing from the Prior Election",
       y = "State Popular Vote",
       title = "Party ID Swing and Popular Vote in Swing States") +
  theme_bw()
```

Trends between partisan swing and state popular vote differ a lot between states. Michigan and Ohio would imply that there might be a small positive correlation, while Georgia would suggest just the opposite. This would imply that perhaps party identification is more predictive of national popular vote than state popular vote. 

```{r, misc notes, echo=FALSE}
# Ask about different methods of estimating Party-ID for each state
# we can use the voter files for 2024
# you can try to look for a historical data set for party
# to weight party ID you can train a model only on party ID and then use ensembling
# super learning would helo make weights that empirically are better
```

## National Popular Vote Predictions

For predictions this week, I make an effort to predict both national popular vote share and the electoral college outcome. 

For national popular vote, I used lasso to make a prediction based on the predictors that we've discussed in previous classes (the economy, incumbency, polling) and this week I added national party identification. 

```{r, national popular vote prediction, echo=FALSE, message=FALSE, warning=FALSE}
nat_data_subset <- 
  nat_data |>
  select(-c(paste0("nat_weeks_left_", 0:4)),
         -candidate, -winner)

nat_train <- 
  nat_data_subset |> 
  filter(year <= 2020)

nat_test <- 
  nat_data_subset |>
  filter(year == 2024)

x.train <- nat_train |>
  ungroup() |> 
  select(-pv, -pv2p, -year) |>
  as.matrix()
y.train <- nat_train$pv
x.test <- nat_test |>
  ungroup() |> 
  select(-pv, -pv2p, -year) |>
  as.matrix()

# Use Lasso for National Popular Vote
lasso.nat <- glmnet(x = x.train, y = y.train, alpha = 1)
set.seed(02138)
cv.lasso.nat <- cv.glmnet(x = x.train, y = y.train, alpha = 1)
lambda.min.lasso <- cv.lasso.nat$lambda.min
mse.lasso <- mean((predict(lasso.nat, s = lambda.min.lasso, newx = x.train) - y.train)^2)

(lasso.nat.pred <- predict(lasso.nat, s = lambda.min.lasso, newx = x.test))

```
The lasso regression found the popular vote to be extremely tight, with Kamala Harris receiving 48.91% and Donald Trump receiving 48.07%. 

```{r, echo=FALSE}
coef(lasso.nat, s = lambda.min.lasso)
```

In the national popular vote predictions, Lasso selected the percent of independents in the country, the swing in party ID from the year prior to the election to the election year, the two party party identification from the previous election, the most recent week of polling, and one earlier week of polling as the most valuable predictors for national popular vote. This would support my theory that party identification may be very important in predicting election outcomes. 

Unfortunately, I spent a lot of time this week compiling and cleaning party identification data and analyzing it's possible impact. Despite many attempts, I was unsuccessful in incorporating it into a state-level model to predict the electoral college this week. I look forward to incorporating party into my state prediction model next week, now that I have the data wrangled and cleaned. 

```{r, misc. notes, echo=FALSE}
# Need to estimate 2024 party id per state
# Ask about value imputation and what assumptions follow when we impute values
# state's historical deviation from national popular vote or from total outcome
# could create a separate model for states without polling
```

```{r, trying to loop through swing states and make lasso predictions, echo=FALSE}
#swing_states = c("Arizona", "Georgia", "Michigan", "North Carolina", "Ohio", "Nevada", "Pennsylvania")
#state_preds <- vector(mode = "list", length = length(swing_states))
#for (state in swing_states) {
  #state_data_state <- 
    #state_data |>
    #filter(state == !!state) |>
    #select(-c(paste0("poll_weeks_left_", 0:4)), -winner, -nat_winner, -state_2pv, -nat_pv, -nat_2pv)
  #print(head(state_data_state))
  #state_data_state_2020 <- 
    #state_data_state |>
    #filter(year <= 2020)
  #print(head(state_data_state_2020))
  
  #mice_impute <- mice(state_data_state_2020, m=5, method="pmm")
  #state_swing_mice <- complete(mice_impute)
  #state_train <- 
    #state_swing_mice |> 
    #filter(year <= 2020)
  
  #state_test <- 
    #state_data_state |>
    #filter(year == 2024)
  #print(head(state_test))
  
  #x.train.state <- state_train |>
    #ungroup() |> 
    #select(-state_pv, -year) |>
    #as.matrix()
  #y.train.state <- state_train$state_pv
  #x.test.state <- state_test |>
    #ungroup() |> 
    #select(-state_pv, -year) |>
    #as.matrix()
  #lasso.state <- glmnet(x = x.train.state, y = y.train.state, alpha = 1)
  #set.seed(02138)
  #cv.lasso.state <- cv.glmnet(x = x.train.state, y = y.train.state, alpha = 1)
  #lambda.min.lasso <- cv.lasso.state$lambda.min
  
  #(lasso.state.pred <- predict(lasso.state, s = lambda.min.lasso, newx = x.test.state))
  
#}
```

```{r, do state level preds for the swing states, echo=FALSE, eval=FALSE}
#state_data_swing_filtered <-
  #state_data_swing |>
  #select(-c(paste0("poll_weeks_left_", 0:4)), -state_margin, -winner, -nat_winner, -nat_pv, -nat_2pv, -state_2pv)
#print(head(state_data_swing_filtered))
#state_data_swing_filtered_pre2020 <- 
  #state_data_swing_filtered |>
  #filter(year <= 2020)
#print(head(state_data_swing_filtered_pre2020))
#mice_impute <- mice(state_data_swing_filtered_pre2020, m=5, method="pmm")
#state_swing_mice <- complete(mice_impute)
  

#x.train.state <- state_swing_mice |> 
  #select(-c(year, state_pv)) |>
  #as.matrix()
#y.train.state <- state_swing_mice |> 
  #select(state_pv) |> 
  #as.matrix()
#x.test.state <- state_data_swing_filtered |> 
  #filter(year == 2024) |> 
  #select(-c(year, state_pv)) |> 
  #as.matrix()

#set.seed(02138)
#lasso.state <- cv.glmnet(x = x.train.state, y = y.train.state, alpha = 0.5)
#lambda.min.lasso.state <- lasso.state$lambda.min

#state.pred <- predict(lasso.state, s = lambda.min.lasso.state, newx = x.test.state[1, ])

```

```{r, state random forest, echo=FALSE, eval=FALSE}
#library(randomForest)
#library(ranger)

#set.seed(02138)
#train.ind <- createDataPartition(state_data$state_pv, p = 0.8, list = FALSE)

#anes_train <- anes_year[train.ind,]
#anes_test <- anes_year[-train.ind,]


```

```{r, modeling notes, echo=FALSE}
# Does it make sense to actually run each state's regression model separately or does that reduce the statistical power of results too much? 
# When I use random forest, does that actually make a model that I could then hypothetically use to bootstrap a bunch of election simulations
# A lot of my theory revolves around weighting partisan ID really high, how exactly can I incorporate that into the model?
# Is there anyway to make it so that when it predicts Dems and Reps it won't be more than 100 or should I re-weight based on percentage (ex. Harris at 52 and Trump at 50, then Harris % of pop vote is 52/102)

# People usually do simulations for values of the polls
# the bootstrap in gov51 is different than what we do here

```
