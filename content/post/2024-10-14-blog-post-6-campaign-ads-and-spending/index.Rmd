---
title: 'Blog Post 6: Campaign Ads and Spending'
author: Alex Heuss
date: '2024-10-14'
slug: blog-post-6-campaign-ads-and-spending
categories: []
tags: []
---
```{r, load in required packages, echo=FALSE, message=FALSE}
library(car)
library(caret)
library(cowplot)
library(curl)
library(CVXR)
library(foreign)
library(geofacet)
library(glmnet)
library(haven)
library(janitor)
library(kableExtra)
library(maps)
library(mlr3)
library(randomForest)
library(ranger)
library(RColorBrewer)
library(rstan)
library(scales)
library(sf)
library(shinystan)
library(tidyverse)
library(viridis)

```

```{r, load in data the way Matt does for state level preds, echo=FALSE, message=FALSE}
d_popvote <- read_csv("data/popvote_1948_2020.csv")
d_state_popvote <- read_csv("data/state_popvote_1948_2020.csv")

# Read elector distribution dataset. 
d_ec <- read_csv("data/corrected_ec_1948_2024.csv")

# Read ads datasets. 
campaign_spending <- read_csv("data/FEC_contributions_by_state_2008_2024.csv")

# Read polling data. 
d_polls <- read_csv("data/national_polls_1968-2024.csv")
d_state_polls <- read_csv("data/state_polls_1968-2024.csv")

# Read turnout data. 
d_turnout <- read_csv("data/state_turnout_1980_2022.csv")
```

This week in class, we discussed the air war in campaigns, particularly the possible impact of advertising over television and radio on the outcome of elections. In section, we also discussed candidate contributions at the state level and how they may be a way to predict election outcomes. 

## Campaign Contribution Visualization

Visualizing campaign contributions per state and that state's popular vote, there does appear to be a positive correlation, although certainly nothing conclusive, as most of the points are centered on one point of the graph (most candiadtes do not receive a ton of contributions from any one state or another). Thus, it is hard to be certain about any trends we may be seeing. 

```{r, contribution data and basic national visualization, echo=FALSE, warning=FALSE, message=FALSE}
# Estimate state-level regression of vote share on campaign spending. 
d_campaign_spending <- d_state_popvote |> 
  mutate(state_abb = state.abb[match(d_state_popvote$state, state.name)]) |> 
  left_join(campaign_spending |> filter(party == "Democrat"), by = c("year" = "election_year", "state_abb" = "contribution_state")) |>
  filter(year >= 2008)

# Basic Visualization of Contributions and Popular Vote

d_campaign_spending |>
  mutate(in_thousands = contribution_receipt_amount/1000) |>
  ggplot(aes(x = in_thousands, y = D_pv)) +
  geom_point() + 
  geom_smooth(method = "lm", se=FALSE, color = "#00AEF3") +
  labs(y = "Democrat Vote Share",
       x = "State Contributions to the Democrat",
       title = "Democratic Party Contributions and Popular Vote For All States") +
  theme_bw()
```

Looking at that relationship in individual swing states, the relationship is inconclusive. One takeaway from this graph is that the relationship between contributions and popular vote varies between states, highlighting the importance of including state fixed effects in any regression analysis. 

```{r, swing states and contributions, echo=FALSE, message=FALSE}
d_campaign_spending |>
  filter(state %in% c("Georgia", "Michigan", "Pennsylvania", "North Carolina", "Wisconsin", "Nevada", "Arizona")) |>
  mutate(in_thousands = contribution_receipt_amount/1000) |>
  ggplot(aes(x = in_thousands, y = D_pv)) +
  geom_point() + 
  geom_smooth(method = "lm", se=FALSE, color = "#00AEF3") +
  labs(y = "Democrat Vote Share",
       x = "State Contributions to the Democrat",
       title = "Democratic Party Contributions and Popular Vote in Swing States") +
  facet_wrap(~ state) +
  theme_bw()
```

```{r, echo=FALSE, message=FALSE}
# Spending + Pop Vote

contribution_lm <- lm(D_pv ~ contribution_receipt_amount + factor(state), 
   data = d_campaign_spending) 
contribution_lm |> summary()

# Log transformation of spending. 

contribution_lm_log <- 
  lm(D_pv ~ log(contribution_receipt_amount) + factor(state), 
   data = d_campaign_spending) 
contribution_lm_log |> summary()

```

Briefly analyzing the results from those regressions, state level contributions may be a predictive variable in election forecasts, when controlling for state. Further, that predictor holds more significance when in logarithmic form. 

## National Popular Vote Prediction

This week I kept my national popular vote prediction model largely the same as last week's, but included also the popular vote for the two prior elections as predictors and updated polling data with the most recent polls. 

```{r, national popular vote predictions, echo=FALSE, message=FALSE, warning=FALSE}
# National Dataset
nat_pop <- read_csv("data/popvote_1948_2020.csv")
nat_party <- read_csv("data/national_party_id.csv") |>
  mutate(swing1 = percent - year_prior,
         swing1_2p = two_party_percent - year_prior_2p) |>
  arrange(year) |>
  group_by(party) |>
  mutate(prior_election = lag(percent, 1),
         prior_election_2p = lag(two_party_percent, 1),
         swing4 = percent - prior_election, 
         swing4_2p = two_party_percent - prior_election_2p)
nat_polls <- read_csv("data/national_polls_1968-2024.csv") |>
  mutate(party = ifelse(party == "DEM", "democrat", "republican")) |>
  filter(weeks_left <= 30) |>
  group_by(party, year, weeks_left) |>
  summarize(nat_poll = mean(poll_support)) |>
  pivot_wider(names_from = weeks_left, values_from = nat_poll)
colnames(nat_polls)[3:33] <- paste0("nat_weeks_left_", 0:30)
nat_econ_q2 <- read_csv("data/fred_econ.csv") |>
  filter(year >= 1968 & quarter == 2) |>
  rename(q2_gdp_growth = GDP_growth_quarterly,
         q2_rdpi_growth = RDPI_growth_quarterly) |>
  select(year, q2_gdp_growth, q2_rdpi_growth)
nat_econ_ann <- read_csv("data/fred_econ.csv") |>
  filter(year >= 1968) |>
  group_by(year) |>
  summarize(GDP = mean(GDP),
            RDPI = mean(RDPI),
            nat_unemployment = mean(unemployment),
            stock_adj_close = mean(sp500_adj_close))
nat_data <- 
  nat_pop |>
  left_join(nat_party, by = c("year", "party")) |>
  group_by(party) |>
  mutate(pv_lag1 = lag(pv, 1),
         pv_lag2 = lag(pv, 2)) |>
  left_join(nat_polls, by = c("year", "party")) |>
  filter(year >= 1968) |>
  left_join(nat_econ_q2, by = "year") |>
  left_join(nat_econ_ann, by = "year")

nat_data_subset <- 
  nat_data |>
  select(-c(paste0("nat_weeks_left_", 0:4)),
         -candidate, -winner)

nat_train <- 
  nat_data_subset |> 
  filter(year <= 2020)

nat_test <- 
  nat_data_subset |>
  filter(year == 2024)

x.train <- nat_train |>
  ungroup() |> 
  select(-pv, -pv2p, -year) |>
  as.matrix()
y.train <- nat_train$pv
x.test <- nat_test |>
  ungroup() |> 
  select(-pv, -pv2p, -year) |>
  as.matrix()

# Use Lasso for National Popular Vote
lasso.nat <- glmnet(x = x.train, y = y.train, alpha = 1)
set.seed(02138)
cv.lasso.nat <- cv.glmnet(x = x.train, y = y.train, alpha = 1)
lambda.min.lasso <- cv.lasso.nat$lambda.min
mse.lasso <- mean((predict(lasso.nat, s = lambda.min.lasso, newx = x.train) - y.train)^2)

(lasso.nat.pred <- predict(lasso.nat, s = lambda.min.lasso, newx = x.test))

```

This week's updated model finds Kamala Harris winning the popular vote with 49.08% and Donald Trump getting 47.91%. The race is still very close, but popular vote totals have diverged a little from last week's predictions with this week's updates.

## Electoral College Prediction

My electoral college model this week includes a number of predictive variables, the most predictive of which are: the latest poll results, the state's results from the past two presidential elections and incumbency. Other variables included in the model are swing in party ID and the economy. 

```{r, create party ID dataset, echo=FALSE, message=FALSE, warning=FALSE}
stateabs <- d_ec |>
  filter(year == 2024) |>
  select(state, stateab)

stateabs_post1968 <- 
  d_ec |>
  filter(year >= 1968) |>
  select(year, state)

anes_party_id <- 
  read_csv("data/anes_timeseries_cdf_csv_20220916.csv") |>
  select(VCF0004, VCF0901b, VCF0302) |>
  rename(year = VCF0004,
         stateab = VCF0901b,
         party = VCF0302) |>
  filter(year >= 1968) |>
  left_join(stateabs, by = "stateab") |>
  select(year, state, party) |>
  mutate(party = case_when(party == 1 ~ "republican",
                           party == 2 ~ "independent",
                           party == 3 ~ "none",
                           party == 4 ~ "other",
                           party == 5 ~ "democrat")) |>
  filter(party == "republican" | party == "democrat" | party == "independent") |>
  group_by(year, state, party) |>
  summarize(count = n()) |>
  pivot_wider(names_from = party, values_from = count) |>
  mutate(democrat = ifelse(is.na(democrat), 0, democrat),
         republican = ifelse(is.na(republican), 0, republican),
         independent = ifelse(is.na(independent), 0, independent),
         state_total = sum(democrat, independent, republican),
         two_party_total = sum(democrat, republican),
         dem_perc = round((democrat/state_total)*100, 2),
         rep_perc = round((republican/state_total)*100, 2),
         ind_perc = round((independent/state_total)*100, 2),
         dem_2p_perc = round((democrat/two_party_total)*100, 2),
         rep_2p_perc = round((republican/two_party_total)*100, 2)) |>
  group_by(state)

d_state_party_id <- 
  stateabs_post1968 |>
  left_join(anes_party_id, by = c("year", "state")) |>
  filter(year != 2024) |>
  select(-democrat, -republican, -independent, -state_total, -two_party_total)
  
```

```{r, 2024 state party ID, echo=FALSE, message=FALSE, warning=FALSE}
stateabbreviations <- unique((d_ec |> filter(stateab != "DC"))$stateab) 
i = 0
for (s in stateabbreviations) {
  # Load in the state's voter files
  voter_file_state_data <- 
    read_csv(paste0("data/state_1pc_samples_aug24/", s, "_sample.csv")) 
  
  # Count the number of voters in the voter files
  voter_file_total_voters <- nrow(voter_file_state_data)
  
  # Clean the data a lot
  voter_file_state_data <- 
    voter_file_state_data |>
    filter(sii_deceased == 0) |>
    rename(stateab = sii_state) |>
    left_join(stateabs, by = "stateab") |>
    mutate(total_voters = voter_file_total_voters,
           dem_perc = ifelse(svi_party_registration == "D", 1, 0),
           rep_perc = ifelse(svi_party_registration == "R", 1, 0),
           ind_perc = ifelse(svi_party_registration == "U", 1, 0))|>
    select(total_voters, dem_perc, rep_perc, ind_perc, state) |>
    group_by(state) |>
    summarize(total_voters = mean(total_voters),
              year = 2024,
              state = state,
              dem_perc = sum(dem_perc, na.rm = TRUE)/total_voters*100,
              rep_perc = sum(rep_perc, na.rm = TRUE)/total_voters*100,
              ind_perc = sum(ind_perc, na.rm = TRUE)/total_voters*100,
              dem_2p_perc = dem_perc / (dem_perc + rep_perc),
              rep_2p_perc = rep_perc / (rep_perc + dem_perc))
  
  voter_file_state_data <- slice(voter_file_state_data, 0:1) |>
    select(-total_voters)
  
  d_state_party_id <- rbind(d_state_party_id, voter_file_state_data)
}



```

```{r, state party cleaning, echo=FALSE, message=FALSE}
d_state_party_id <- 
  d_state_party_id |>
  group_by(state) |>
  arrange(year) |>
  mutate(dem_perc_lag4 = lag(dem_perc, 1),
         rep_perc_lag4 = lag(rep_perc, 1))
```

```{r, electoral college preds for states with polls, echo=FALSE, message=FALSE, warning=FALSE}
d_pollav_state <- d_state_polls |>
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |>
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))

d_state_econ <- 
  read_csv("data/Historical_State_Unemployment.csv") |>
  mutate(year = format(as.Date(date), "%Y")) |>
  mutate(year = as.double(year)) |>
  group_by(state, year) |>
  summarize(avg_state_unemployment = mean(unemployment)) |>
  left_join(nat_econ_ann, by = "year") |>
  left_join(nat_econ_q2, by = "year")

# Merge data.
d <- d_pollav_state |>
  left_join(d_state_party_id, by = c("year", "state")) |>
  left_join(d_state_popvote, by = c("year", "state")) |>
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |>
  left_join(d_turnout, by = c("year", "state")) |>
  left_join(d_state_econ, by = c("state", "year")) |>
  filter(year >= 1980) |>
  ungroup()

# Sequester states for which we have polling data for 2024.

states.2024 <- unique(d$state[d$year == 2024])
states.2024 <- states.2024[-which(states.2024 == "Nebraska Cd 2")]

d <- d |>
  filter(state %in% states.2024)

# Separate into training and testing for simple poll prediction model. 
d.train <- d |> filter(year < 2024) |> select(year, state, D_pv, latest_pollav_DEM, mean_pollav_DEM, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4) |> drop_na()
d.test <- d |> filter(year == 2024) |> select(year, state, D_pv, latest_pollav_DEM, mean_pollav_DEM, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4)

# Add back in lagged vote share for 2024. 
t <- d |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv_lag1 = lag(D_pv, 1),
    R_pv_lag1 = lag(R_pv, 1), 
    D_pv_lag2 = lag(D_pv, 2),
    R_pv_lag2 = lag(R_pv, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv, R_pv, D_pv_lag1, R_pv_lag1, D_pv_lag2, R_pv_lag2)

# Subset testing data to only relevant variables for our simple model. 
d.test <- d.test |> 
  select(-c(D_pv, D_pv_lag1, D_pv_lag2)) |> 
  left_join(t, by = c("state", "year"))

# Standard frequentist linear regression. 
reg.ols <- lm(D_pv ~ latest_pollav_DEM + mean_pollav_DEM + D_pv_lag1 + D_pv_lag2 + incumbent_party + q2_gdp_growth + avg_state_unemployment + dem_perc_lag4 + rep_perc_lag4 + state, 
              data = d.train)
summary(reg.ols)
pred.ols.dem <- predict(reg.ols, newdata = d.test)

# Create dataset to summarize winners and EC vote distributions. 
win_pred <- data.frame(state = d.test$state,
                       year = rep(2024, length(d.test$state)),
                       simp_pred_dem = pred.ols.dem,
                       simp_pred_rep = 100 - pred.ols.dem) |> 
            mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican")) |>
            left_join(d_ec, by = c("state", "year"))

```

```{r, exact same thing but for states without polls, echo=FALSE, message=FALSE, warning=FALSE}
missing_state_polls <- 
  read_csv("data/missing_poll_states_csv.csv")
missing_state_polls <- 
  missing_state_polls |>
  filter(party == "DEM" & !state %in% states.2024) |>
  mutate(latest_pollav_REP = poll_support,
         latest_pollav_DEM = poll_support,
         mean_pollav_REP = poll_support,
         mean_pollav_DEM = poll_support) |>
  select(year, state, latest_pollav_REP, latest_pollav_DEM, mean_pollav_REP, mean_pollav_DEM)
missing_state_polls <- rbind(d_pollav_state, missing_state_polls)

d_no_polls <- missing_state_polls |>
  left_join(d_state_party_id, by = c("year", "state")) |>
  left_join(d_state_popvote, by = c("year", "state")) |>
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |>
  left_join(d_turnout, by = c("year", "state")) |>
  left_join(d_state_econ, by = c("state", "year")) |>
  filter(year >= 1980 & state != "Nebraska Cd 2") |>
  ungroup()|>
  filter(!state %in% states.2024)

# Separate into training and testing for simple poll prediction model. 
d.train.nopolls <- d_no_polls |> filter(year < 2024) |> select(year, state, D_pv, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4) |> drop_na()
d.test.nopolls <- d_no_polls |> filter(year == 2024) |> select(year, state, D_pv, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4)

# Add back in lagged vote share for 2024. 
t.nopolls <- d_no_polls |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv_lag1 = lag(D_pv, 1),
    R_pv_lag1 = lag(R_pv, 1), 
    D_pv_lag2 = lag(D_pv, 2),
    R_pv_lag2 = lag(R_pv, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv, R_pv, D_pv_lag1, R_pv_lag1, D_pv_lag2, R_pv_lag2)

# Subset testing data to only relevant variables for our simple model. 
d.test.nopolls <- d.test.nopolls |> 
  select(-c(D_pv, D_pv_lag1, D_pv_lag2)) |> 
  left_join(t.nopolls, by = c("state", "year"))

# Standard frequentist linear regression. 
reg.ols.nopolls <- lm(D_pv ~ D_pv_lag1 + D_pv_lag2 + incumbent_party + q2_gdp_growth + avg_state_unemployment + dem_perc_lag4 + rep_perc_lag4 + state, 
              data = d.train.nopolls)
summary(reg.ols.nopolls)
pred.ols.dem.nopolls <- predict(reg.ols.nopolls, newdata = d.test.nopolls)

# Create dataset to summarize winners and EC vote distributions. 
win_pred_nopolls <- data.frame(state = d.test.nopolls$state,
                       year = rep(2024, length(d.test.nopolls$state)),
                       simp_pred_dem = pred.ols.dem.nopolls,
                       simp_pred_rep = 100 - pred.ols.dem.nopolls) |> 
            mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican")) |>
            left_join(d_ec, by = c("state", "year"))

```

Looking at the results below, my state-level model predicts that Donald Trump will win 272 votes and Kamala Harris will win 263. The District of Columbia was not included in my model, but it's 3 electoral college votes will almost certainly go to Harris, bringing her total to 266 and the presidential race results within 6 electoral college votes. 

```{r, visualize results, echo=FALSE, message=FALSE}
all_preds <- rbind(win_pred, win_pred_nopolls)

states_map <- map_data("state")
all_preds |>
  rename(Winner = winner) |>
  group_by(Winner) |>
  summarize(`States Won` = n(), Electors = sum(electors)) |>
  knitr::kable()

all_preds |>
  mutate(region = tolower(state),
         Margin = simp_pred_dem - simp_pred_rep) |>
  left_join(states_map, by = "region") |>
  ggplot(aes(long, lat, group=group)) + 
  geom_polygon(aes(fill = Margin), color = "black") + 
  scale_fill_gradient2(midpoint = 0, low = "#E81B23", mid = "white", high = "#00AEF3") +
  labs(title = "Electoral College Prediction Map") +
  theme_void()
  

```

## Conclusion

I'm finally close to being happy with my prediction models this week. Next week, I hope to incorporate more Lasso regression or machine learning techniques into my models to make my predictions more sophisticated and help to keep my model from being overfitted. 


