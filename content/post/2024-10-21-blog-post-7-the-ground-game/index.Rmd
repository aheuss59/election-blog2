---
title: 'Blog Post 7: The Ground Game'
author: Alex Heuss
date: '2024-10-21'
slug: blog-post-7-the-ground-game
categories: []
tags: []
---

```{r, load in required packages, echo=FALSE, message=FALSE}
library(car)
library(caret)
library(cowplot)
library(curl)
library(CVXR)
library(foreign)
library(geofacet)
library(glmnet)
library(haven)
library(janitor)
library(kableExtra)
library(maps)
library(mlr3)
library(randomForest)
library(ranger)
library(RColorBrewer)
library(rstan)
library(scales)
library(sf)
library(shinystan)
library(tidyverse)
library(viridis)
library(mice)
```

```{r, load in the nat data, echo=FALSE, message=FALSE}
# National Dataset
nat_pop <- read_csv("data/popvote_1948_2020.csv")
nat_party <- read_csv("data/national_party_id.csv") |>
  mutate(swing1 = percent - year_prior,
         swing1_2p = two_party_percent - year_prior_2p) |>
  arrange(year) |>
  group_by(party) |>
  mutate(prior_election = lag(percent, 1),
         prior_election_2p = lag(two_party_percent, 1),
         swing4 = percent - prior_election, 
         swing4_2p = two_party_percent - prior_election_2p)
nat_polls <- read_csv("data/national_polls_1968-2024.csv") |>
  mutate(party = ifelse(party == "DEM", "democrat", "republican")) |>
  filter(weeks_left <= 30) |>
  group_by(party, year, weeks_left) |>
  summarize(nat_poll = mean(poll_support)) |>
  pivot_wider(names_from = weeks_left, values_from = nat_poll)
colnames(nat_polls)[3:33] <- paste0("nat_weeks_left_", 0:30)
nat_econ_q2 <- read_csv("data/fred_econ.csv") |>
  filter(year >= 1968 & quarter == 2) |>
  rename(q2_gdp_growth = GDP_growth_quarterly,
         q2_rdpi_growth = RDPI_growth_quarterly) |>
  select(year, q2_gdp_growth, q2_rdpi_growth)
nat_econ_ann <- read_csv("data/fred_econ.csv") |>
  filter(year >= 1968) |>
  group_by(year) |>
  summarize(GDP = mean(GDP),
            RDPI = mean(RDPI),
            nat_unemployment = mean(unemployment),
            stock_adj_close = mean(sp500_adj_close))
nat_data <- 
  nat_pop |>
  left_join(nat_party, by = c("year", "party")) |>
  group_by(party) |>
  mutate(pv_lag1 = lag(pv, 1),
         pv_lag2 = lag(pv, 2)) |>
  left_join(nat_polls, by = c("year", "party")) |>
  filter(year >= 1968) |>
  left_join(nat_econ_q2, by = "year") |>
  left_join(nat_econ_ann, by = "year")

```

```{r, load in the state data, echo=FALSE, message=FALSE, warning=FALSE}
d_popvote <- read_csv("data/popvote_1948_2020.csv")
d_state_popvote <- read_csv("data/state_popvote_1948_2020.csv")

# Read elector distribution dataset. 
d_ec <- read_csv("data/corrected_ec_1948_2024.csv")

# Read ads datasets. 
campaign_spending <- read_csv("data/FEC_contributions_by_state_2008_2024.csv")

# Read polling data. 
d_polls <- read_csv("data/national_polls_1968-2024.csv")
d_state_polls <- read_csv("data/state_polls_1968-2024.csv")

# Read turnout data. 
d_turnout <- read_csv("data/state_turnout_1980_2022.csv")

d_campaign_spending <- d_state_popvote |> 
  mutate(state_abb = state.abb[match(d_state_popvote$state, state.name)]) |> 
  left_join(campaign_spending |> filter(party == "Democrat"), by = c("year" = "election_year", "state_abb" = "contribution_state")) |>
  filter(year >= 2008)

d_pollav_state <- d_state_polls |>
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |>
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))

d_state_econ <- 
  read_csv("data/Historical_State_Unemployment.csv") |>
  mutate(year = format(as.Date(date), "%Y")) |>
  mutate(year = as.double(year)) |>
  group_by(state, year) |>
  summarize(avg_state_unemployment = mean(unemployment)) |>
  left_join(nat_econ_ann, by = "year") |>
  left_join(nat_econ_q2, by = "year")

```

```{r, create state level historical party ID, echo=FALSE, message=FALSE, warning=FALSE}
stateabs <- d_ec |>
  filter(year == 2024) |>
  select(state, stateab)

stateabs_post1968 <- 
  d_ec |>
  filter(year >= 1968) |>
  select(year, state)

anes_party_id <- 
  read_csv("data/anes_timeseries_cdf_csv_20220916.csv") |>
  select(VCF0004, VCF0901b, VCF0302) |>
  rename(year = VCF0004,
         stateab = VCF0901b,
         party = VCF0302) |>
  filter(year >= 1968) |>
  left_join(stateabs, by = "stateab") |>
  select(year, state, party) |>
  mutate(party = case_when(party == 1 ~ "republican",
                           party == 2 ~ "independent",
                           party == 3 ~ "none",
                           party == 4 ~ "other",
                           party == 5 ~ "democrat")) |>
  filter(party == "republican" | party == "democrat" | party == "independent") |>
  group_by(year, state, party) |>
  summarize(count = n()) |>
  pivot_wider(names_from = party, values_from = count) |>
  mutate(democrat = ifelse(is.na(democrat), 0, democrat),
         republican = ifelse(is.na(republican), 0, republican),
         independent = ifelse(is.na(independent), 0, independent),
         state_total = sum(democrat, independent, republican),
         two_party_total = sum(democrat, republican),
         dem_perc = round((democrat/state_total)*100, 2),
         rep_perc = round((republican/state_total)*100, 2),
         ind_perc = round((independent/state_total)*100, 2),
         dem_2p_perc = round((democrat/two_party_total)*100, 2),
         rep_2p_perc = round((republican/two_party_total)*100, 2)) |>
  group_by(state)

d_state_party_id <- 
  stateabs_post1968 |>
  left_join(anes_party_id, by = c("year", "state")) |>
  filter(year != 2024) |>
  select(-democrat, -republican, -independent, -state_total, -two_party_total) |>
  mutate(total_voters = NA)
```

```{r, loop for 2024 Party ID, echo=FALSE, message=FALSE, warning=FALSE}
stateabbreviations <- unique((d_ec |> filter(stateab != "DC"))$stateab) 
i = 0
for (s in stateabbreviations) {
  # Load in the state's voter files
  voter_file_state_data <- 
    read_csv(paste0("data/state_1pc_samples_aug24/", s, "_sample.csv")) 
  
  # Count the number of voters in the voter files
  voter_file_total_voters <- nrow(voter_file_state_data)
  
  # Clean the data a lot
  voter_file_state_data <- 
    voter_file_state_data |>
    filter(sii_deceased == 0) |>
    rename(stateab = sii_state) |>
    left_join(stateabs, by = "stateab") |>
    mutate(total_voters = voter_file_total_voters,
           dem_perc = ifelse(svi_party_registration == "D", 1, 0),
           rep_perc = ifelse(svi_party_registration == "R", 1, 0),
           ind_perc = ifelse(svi_party_registration == "U", 1, 0))|>
    select(total_voters, dem_perc, rep_perc, ind_perc, state) |>
    group_by(state) |>
    summarize(total_voters = mean(total_voters),
              year = 2024,
              state = state,
              dem_perc = sum(dem_perc, na.rm = TRUE)/total_voters*100,
              rep_perc = sum(rep_perc, na.rm = TRUE)/total_voters*100,
              ind_perc = sum(ind_perc, na.rm = TRUE)/total_voters*100,
              dem_2p_perc = dem_perc / (dem_perc + rep_perc),
              rep_2p_perc = rep_perc / (rep_perc + dem_perc))
  
  voter_file_state_data <- slice(voter_file_state_data, 0:1)
  
  d_state_party_id <- rbind(d_state_party_id, voter_file_state_data)
}
```

```{r, clean state party data, echo=FALSE, message=FALSE}
d_state_party_id <- 
  d_state_party_id |>
  group_by(state) |>
  arrange(year) |>
  mutate(dem_perc_lag4 = lag(dem_perc, 1),
         rep_perc_lag4 = lag(rep_perc, 1),
         dem_perc_swing = dem_perc - dem_perc_lag4,
         rep_perc_swing = rep_perc - rep_perc_lag4)

open_primaries <- 
  d_state_party_id |>
  filter(year == 2024) |>
  mutate(open_primary_2024 = ifelse(ind_perc > dem_perc + rep_perc, TRUE, FALSE)) |>
  select(state, open_primary_2024)
  
```

## National Popular Vote Prediction

This week, I started by re-running my national popular vote prediction model from past weeks with updated poll numbers from this week. 

```{r, perform national pop vote lasso prediction, echo=FALSE, message=FALSE, warning=FALSE}
# Subset to the weeks_left we have polling data for
nat_data_subset <- 
  nat_data |>
  select(-c(paste0("nat_weeks_left_", 0:3)),
         -candidate, -winner)
# Train and Test splits
nat_train <- 
  nat_data_subset |> 
  filter(year <= 2020)
nat_test <- 
  nat_data_subset |>
  filter(year == 2024)
x.train <- nat_train |>
  ungroup() |> 
  select(-pv, -pv2p, -year) |>
  as.matrix()
y.train <- nat_train$pv
x.test <- nat_test |>
  ungroup() |> 
  select(-pv, -pv2p, -year) |>
  as.matrix()

# Use Lasso for National Popular Vote
lasso.nat <- glmnet(x = x.train, y = y.train, alpha = 1)
set.seed(02138)
cv.lasso.nat <- cv.glmnet(x = x.train, y = y.train, alpha = 1)
lambda.min.lasso <- cv.lasso.nat$lambda.min
mse.lasso <- mean((predict(lasso.nat, s = lambda.min.lasso, newx = x.train) - y.train)^2)

(lasso.nat.pred <- predict(lasso.nat, s = lambda.min.lasso, newx = x.test))

```

The model's predictions have not changed much from last week, Kamala Harris' popular vote share shrank by about 0.02 percentage points and Donald Trump's grew by 0.001 percentage points. It seems like if I continue to hold my LASSO model constant, the two candidates will probably remain about the same in the popular vote share prediction unless there are significant polling shifts. 

## Electoral College Predictions

In my electoral prediction model this week, I updated the polling data with polls from this week and changed the value I use to represent partisan identification. Last week, I made a mistake in my model and instead of using swing in party identification from one election to the next, I used the partisan identification of the state during the last election. I corrected it in this week's model. I also added a variable for open primaries (states that, in 2024, have a lot more registered independent voters than democrats and republicans combined), and controlled for it in an attempt to minimize the issues with the party identification variable for 2024. 

```{r, predict electoral college for states with polls, echo=FALSE, message=FALSE}
# Merge data.
d <- d_pollav_state |>
  left_join(d_state_party_id, by = c("year", "state")) |>
  left_join(d_state_popvote, by = c("year", "state")) |>
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |>
  left_join(d_turnout, by = c("year", "state")) |>
  left_join(d_state_econ, by = c("state", "year")) |>
  left_join(open_primaries, by = c("state")) |>
  filter(year >= 1980) |>
  ungroup()

# Take a minute to figure out an imputation method for states with open primaries whose 2024 partisan identification is flawed

# Sequester states for which we have polling data for 2024.

states.2024 <- unique(d$state[d$year == 2024])
states.2024 <- states.2024[-which(states.2024 == "Nebraska Cd 2")]

d<- 
  d |>
  filter(state %in% states.2024)

# Separate into training and testing for simple poll prediction model. 
d.train <- d |> filter(year < 2024) |> select(year, state, D_pv, latest_pollav_DEM, mean_pollav_DEM, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4, dem_perc_swing, rep_perc_swing, open_primary_2024) |> drop_na()

d.test <- d |> filter(year == 2024) |> select(year, state, D_pv, latest_pollav_DEM, mean_pollav_DEM, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4, dem_perc_swing, rep_perc_swing, open_primary_2024)

# Add back in lagged vote share for 2024. 
t <- d |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv_lag1 = lag(D_pv, 1),
    R_pv_lag1 = lag(R_pv, 1), 
    D_pv_lag2 = lag(D_pv, 2),
    R_pv_lag2 = lag(R_pv, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv, R_pv, D_pv_lag1, R_pv_lag1, D_pv_lag2, R_pv_lag2)

# Subset testing data to only relevant variables for our simple model. 
d.test <- d.test |> 
  select(-c(D_pv, D_pv_lag1, D_pv_lag2)) |> 
  left_join(t, by = c("state", "year"))

# Standard frequentist linear regression. 
reg.ols <- lm(D_pv ~ latest_pollav_DEM + mean_pollav_DEM + D_pv_lag1 + D_pv_lag2 + incumbent_party + q2_gdp_growth + avg_state_unemployment + dem_perc_swing + rep_perc_swing + open_primary_2024 + state, 
              data = d.train)
pred.ols.dem <- predict(reg.ols, newdata = d.test)

# Create dataset to summarize winners and EC vote distributions. 
win_pred <- data.frame(state = d.test$state,
                       year = rep(2024, length(d.test$state)),
                       simp_pred_dem = pred.ols.dem,
                       simp_pred_rep = 100 - pred.ols.dem) |> 
            mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican")) |>
            left_join(d_ec, by = c("state", "year"))

```


```{r, predict electoral college for states without polls, echo=FALSE, message=FALSE}
missing_state_polls <- 
  read_csv("data/missing_poll_states_csv.csv")
missing_state_polls <- 
  missing_state_polls |>
  filter(party == "DEM" & !state %in% states.2024) |>
  mutate(latest_pollav_REP = poll_support,
         latest_pollav_DEM = poll_support,
         mean_pollav_REP = poll_support,
         mean_pollav_DEM = poll_support) |>
  select(year, state, latest_pollav_REP, latest_pollav_DEM, mean_pollav_REP, mean_pollav_DEM)
missing_state_polls <- rbind(d_pollav_state, missing_state_polls)

d_no_polls <- missing_state_polls |>
  left_join(d_state_party_id, by = c("year", "state")) |>
  left_join(d_state_popvote, by = c("year", "state")) |>
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |>
  left_join(d_turnout, by = c("year", "state")) |>
  left_join(d_state_econ, by = c("state", "year")) |>
  left_join(open_primaries, by = "state") |>
  filter(year >= 1980 & state != "Nebraska Cd 2") |>
  ungroup()|>
  filter(!state %in% states.2024)

# Separate into training and testing for simple poll prediction model. 
d.train.nopolls <- d_no_polls |> filter(year < 2024) |> select(year, state, D_pv, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4, dem_perc_swing, rep_perc_swing, open_primary_2024) |> drop_na()
d.test.nopolls <- d_no_polls |> filter(year == 2024) |> select(year, state, D_pv, 
                                              D_pv_lag1, D_pv_lag2, incumbent_party, avg_state_unemployment, q2_gdp_growth, dem_perc, rep_perc, ind_perc, dem_perc_lag4, rep_perc_lag4, dem_perc_swing, rep_perc_swing, open_primary_2024)

# Add back in lagged vote share for 2024. 
t.nopolls <- d_no_polls |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv_lag1 = lag(D_pv, 1),
    R_pv_lag1 = lag(R_pv, 1), 
    D_pv_lag2 = lag(D_pv, 2),
    R_pv_lag2 = lag(R_pv, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv, R_pv, D_pv_lag1, R_pv_lag1, D_pv_lag2, R_pv_lag2)

# Subset testing data to only relevant variables for our simple model. 
d.test.nopolls <- d.test.nopolls |> 
  select(-c(D_pv, D_pv_lag1, D_pv_lag2)) |> 
  left_join(t.nopolls, by = c("state", "year"))

# Standard frequentist linear regression. 
reg.ols.nopolls <- lm(D_pv ~ D_pv_lag1 + D_pv_lag2 + incumbent_party + q2_gdp_growth + avg_state_unemployment + dem_perc_swing + rep_perc_swing + open_primary_2024 + state, 
              data = d.train.nopolls)
pred.ols.dem.nopolls <- predict(reg.ols.nopolls, newdata = d.test.nopolls)

# Create dataset to summarize winners and EC vote distributions. 
win_pred_nopolls <- data.frame(state = d.test.nopolls$state,
                       year = rep(2024, length(d.test.nopolls$state)),
                       simp_pred_dem = pred.ols.dem.nopolls,
                       simp_pred_rep = 100 - pred.ols.dem.nopolls) |> 
            mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican")) |>
            left_join(d_ec, by = c("state", "year"))

```

```{r, breakdown electoral college results, echo=FALSE, message=FALSE}
all_preds <- rbind(win_pred, win_pred_nopolls)

states_map <- map_data("state")
all_preds |>
  rename(Winner = winner) |>
  group_by(Winner) |>
  summarize(`States Won` = n(), Electors = sum(electors)) |>
  knitr::kable()
```

Taking a look at the full election results, once again Kamala Harris loses the electoral college. DC is also not included in my model this week, but will almost certainly go to Harris, which would bring teh vote totals to 266 for Harris and 272 for Trump. 

The next table visualizes the swing state breakdown. 

```{r, swing state specific breakdown, echo=FALSE, message=FALSE}
all_preds |>
  filter(state %in% c("Michigan", "Wisconsin", "Pennsylvania", "Georgia", "North Carolina", "Arizona", "Nevada")) |>
  mutate(Margin = simp_pred_dem - simp_pred_rep) |>
  rename(State = state, Winner = winner) |>
  select(State, Winner, Margin) |>
  arrange(Winner) |>
  knitr::kable()
```

My model predicts Harris to win Michigan, Pennsylvania and Wisconsin while Trump wins Arizona, Georgia, Nevada and North Carolina. 

Finally, here's a look at the full map. 

```{r, map, echo=FALSE, message=FALSE}
all_preds |>
  mutate(region = tolower(state),
         Margin = simp_pred_dem - simp_pred_rep) |>
  left_join(states_map, by = "region") |>
  ggplot(aes(long, lat, group=group)) + 
  geom_polygon(aes(fill = Margin), color = "black") + 
  scale_fill_gradient2(midpoint = 0, low = "#E81B23", mid = "white", high = "#00AEF3") +
  labs(title = "Electoral College Prediction Map") +
  theme_void()
```

## An Attempt at Lasso Regression for Electoral College Predictions

This week, I also wanted to try using a more sophisticated method for model selection and tried to run a LASSO prediction on my state-level data. After struggling with imputation and matrices for awhile, my model promptly predicted that Kamala Harris would win at least -35,000 percent of the vote share and Donald Trump at least -81,000. Due to the highly inaccurate nature of these predictions, I instead took the features LASSO suggested and fed them back into a linear model. 

This model spit out some possible, but not necessarily realistic estimates for the states that currently have polling data (mostly toss up states or states that lean one way or another). 

```{r, trying state-level lasso, echo=FALSE, message=FALSE, warning=FALSE, results=FALSE}

# Separate into training and testing for simple poll prediction model. 

d.train.lasso <- d |> filter(year < 2024)
mice_impute <- mice(d.train.lasso, m=5, method="cart")
d.train.lasso <- complete(mice_impute) 
d.train.lasso <- d.train.lasso |>
  select(-c(43:55), -R_pv2p, -D_pv2p, -year, -total_voters, -votes_D, -votes_R, -total_votes, -two_party_votes, -party, -winner, -candidate, -pv, -pv2p) |>
  drop_na()
d.test.lasso <- d |> filter(year == 2024) 

# Add back in lagged vote share for 2024. 
t.lasso <- d |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv_lag1 = lag(D_pv, 1),
    R_pv_lag1 = lag(R_pv, 1), 
    D_pv_lag2 = lag(D_pv, 2),
    R_pv_lag2 = lag(R_pv, 2),
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1),
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv_lag1, R_pv_lag1, D_pv_lag2, R_pv_lag2, D_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag1, R_pv2p_lag2)

# Subset testing data to only relevant variables for our simple model. 
d.test.lasso <- d.test.lasso |> 
  select(-c(D_pv, D_pv_lag1, D_pv_lag2, R_pv, R_pv_lag1, R_pv_lag2, D_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag1, R_pv2p_lag2)) |> 
  left_join(t.lasso, by = c("state", "year"))

x.train.state <- d.train.lasso |>
  ungroup() |>
  select(-D_pv, -R_pv, -state) 

scaling_params <- apply(x.train.state, 2, function(x) c(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE)))

x.train.state <- scale(x.train.state, center = scaling_params["mean", ], scale = scaling_params["sd", ]) |>
  as.matrix()

y.train.state <- d.train.lasso$D_pv
y.train.state.reps <- d.train.lasso$R_pv
x.test.state <- d.test.lasso |>
  ungroup() |> 
  select(-c(33:45), -R_pv2p, -D_pv2p, -year, -total_voters, -votes_D, -votes_R, -total_votes, -two_party_votes, -party, -winner, -candidate, -pv, -pv2p, -state) 

x.test.state <-
  scale(x.test.state, center = scaling_params["mean", ], scale = scaling_params["sd", ]) |>
  as.matrix()

#Predict Dems

lasso.state.dems <- glmnet(x = x.train.state, y = y.train.state, alpha = 1)
set.seed(02138)
cv.lasso.state.dems <- cv.glmnet(x = x.train.state, y = y.train.state, alpha = 1)
lambda.min.lasso.state.dems <- cv.lasso.state.dems$lambda.min
mse.lasso.state.dems <- mean((predict(lasso.state.dems, s = lambda.min.lasso.state.dems, newx = x.train.state) - y.train.state)^2)

lasso.state.pred.dems <- predict(lasso.state.dems, s = lambda.min.lasso.state.dems, newx = x.test.state)

#coef(lasso.state.dems, s = lambda.min.lasso.state.dems)

#Predict Reps

lasso.state.reps <- glmnet(x = x.train.state, y = y.train.state.reps, alpha = 1)
set.seed(02138)
cv.lasso.state.reps <- cv.glmnet(x = x.train.state, y = y.train.state.reps, alpha = 1)
lambda.min.lasso.state.reps <- cv.lasso.state.reps$lambda.min
mse.lasso.state.reps <- mean((predict(lasso.state.reps, s = lambda.min.lasso.state.reps, newx = x.train.state) - y.train.state.reps)^2)

lasso.state.pred.reps <- predict(lasso.state.reps, s = lambda.min.lasso.state.reps, newx = x.test.state)

# coef(lasso.state.reps, s = lambda.min.lasso.state.reps)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Predict dem share

reg.ols.lasso.polls <- lm(D_pv ~ latest_pollav_REP + latest_pollav_DEM + mean_pollav_REP + mean_pollav_DEM  + dem_perc_lag4 + rep_perc_lag4 + D_pv_lag1 + R_pv_lag1 + D_pv_lag2 + R_pv_lag2 + incumbent + incumbent_party + prev_admin + avg_state_unemployment + GDP + nat_unemployment + stock_adj_close + q2_gdp_growth + q2_rdpi_growth, 
              data = d.train.lasso)
pred.ols.lasso.polls <- predict(reg.ols.lasso.polls, newdata = d.test.lasso)

lasso.state.pred <- data.frame(state = d.test$state,
                       simp_pred_dem = pred.ols.lasso.polls,
                       simp_pred_rep = 100 - pred.ols.lasso.polls) |> 
            mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican"))

lasso.state.pred |> knitr::kable()

```

These results would suggest a pretty rough outcome for the Democrats in November. I unfortunately was unable to secure a possible prediction for vote share using the LASSO linear regression coefficients for states without polling data (the Democrats managed negative vote share and the Republicans more than 100). I hope to correct the error in my LASSO model for next week, but this week will have to stick with last week's model detailed in the previous section. 

```{r, echo=FALSE, eval=FALSE, message=FALSE}
d.train.lasso.nopolls <- d_no_polls |> filter(year < 2024) |>
  select(-c(43:55), -R_pv2p, -D_pv2p, -year, -total_voters, -votes_D, -votes_R, -total_votes, -two_party_votes, -party, -winner, -candidate, -pv, -pv2p) |>
  drop_na()
d.test.lasso.nopolls <- d_no_polls |> filter(year == 2024)
# Add back in lagged vote share for 2024. 
t.lasso.nopolls <- d_no_polls |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv_lag1 = lag(D_pv, 1),
    R_pv_lag1 = lag(R_pv, 1), 
    D_pv_lag2 = lag(D_pv, 2),
    R_pv_lag2 = lag(R_pv, 2),
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1),
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv_lag1, R_pv_lag1, D_pv_lag2, R_pv_lag2, D_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag1, R_pv2p_lag2)

# Subset testing data to only relevant variables for our simple model. 
d.test.lasso.nopolls <- d.test.lasso.nopolls |> 
  select(-c(D_pv, D_pv_lag1, D_pv_lag2, R_pv, R_pv_lag1, R_pv_lag2, D_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag1, R_pv2p_lag2)) |> 
  left_join(t.lasso.nopolls, by = c("state", "year"))

reg.ols.lasso.nopolls <- lm(D_pv ~ dem_perc_lag4 + rep_perc_lag4 + D_pv_lag1 + R_pv_lag1 + D_pv_lag2 + R_pv_lag2 + incumbent + incumbent_party + prev_admin + avg_state_unemployment + GDP + nat_unemployment + stock_adj_close + q2_gdp_growth + q2_rdpi_growth, 
              data = d.train.lasso.nopolls)
pred.ols.lasso.nopolls <- predict(reg.ols.lasso.nopolls, newdata = d.test.lasso.nopolls)

```










